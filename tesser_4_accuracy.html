<head>
<title>Daisy App Project |ARL Tech. CVIT</title>
<link href="https://vandnachaturvedi.github.io/CVIT_TIMELINE/styles.css" rel="stylesheet" type="text/css" ></head>

<body>
<h2>Accuracy of Tesseract v4.0 OCR<h2>

<table id="table1">
	<caption><b> Table: Accuracy Of Tesseract v4.0</caption>
	<tr>
		<th>Samples</th>
		<th>Word-wise</th>
		<th>Character-wise</th>
		<th>Insights/th>
	</tr>
	<tr>
		<td>Font variation</td>
		<td>97.84%</td>
		<td>99.65%</td>
		<td>1752 Characters; 279 Words; 14 Sentences</td>
	</tr>
	<tr>
		<td>Bad Scanning Quality</td>
		<td>83.6%</td>
		<td>87.05%</td>
		<td>3191 Characters; 576 Words; 48 Sentences</td>
	</tr>
	<tr>
		<td>Context difference</td>
		<td>98.41%</td>
		<td>99.53%</td>
		<td>3210 Characters; 504 Words; 36 Sentences</td>
	</tr>
</table>
<!--
<br>
<p>As suggested by PK Sir, starting a pilot study to estimate cost and time for different <i>N</i>, <i>M</i>, <i>K</i>:</p>

<ul>
	<li>Planning to first annotate <i>M=200</i> images with <i>K=3</i> descriptions each. This requires at least 3 annotators with very good grasp of English.</li>
	<li>Will get an idea how varied the descriptions can be for each face, hence have accurate annotation guidelines for final full-scale annotation</li>
	<li>It will give us an approximate of how many unique description classes (N) we will have in the end.</li>
	<li>Will get approximate cost / image, which is largely dependent on <i>N</i>.</li>
</ul>

<br>
<p>Found out that Amazon Mechanical Turk Requester account isnâ€™t available to Indian users. Surveyed other similar platforms:</p>

<ul>
	<li>Many reputed ones assure better annotation quality at almost the same / lesser prices than Mechanical Turk.</li>
	<li>Will have more information regarding these platforms by next week.</li>
</ul>
-->
</body>
